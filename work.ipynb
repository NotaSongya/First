{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bff3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\Anaconda\\envs\\mytensor\\lib\\site-packages\\keras\\backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow.compat.v1 as tf\n",
    "# 导入tensorflow.keras\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "#from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import kt_utils \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "import resnets_utils \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# 指定GPU编号，如果有多个GPU可以使用\"0,1,2\"这样的方式指定多个GPU\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import resnets_utils \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58fff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    实现图3的恒等块\n",
    "    \n",
    "    参数：\n",
    "        X - 输入的tensor类型的数据，维度为( m, n_H_prev, n_W_prev, n_H_prev )\n",
    "        f - 整数，指定主路径中间的CONV窗口的维度\n",
    "        filters - 整数列表，定义了主路径每层的卷积层的过滤器数量\n",
    "        stage - 整数，根据每层的位置来命名每一层，与block参数一起使用。\n",
    "        block - 字符串，据每层的位置来命名每一层，与stage参数一起使用。\n",
    "        \n",
    "    返回：\n",
    "        X - 恒等块的输出，tensor类型，维度为(n_H, n_W, n_C)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #定义命名规则\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    #获取过滤器\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    #保存输入数据，将会用于为主路径添加捷径\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #主路径的第一部分\n",
    "    ##卷积层\n",
    "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(1,1) ,padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ##归一化\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    ##使用ReLU激活函数\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    #主路径的第二部分\n",
    "    ##卷积层\n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f),strides=(1,1), padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ##归一化\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    ##使用ReLU激活函数\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    \n",
    "    #主路径的第三部分\n",
    "    ##卷积层\n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    ##归一化\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "    ##没有ReLU激活函数\n",
    "    \n",
    "    #最后一步：\n",
    "    ##将捷径与输入加在一起\n",
    "    X = Add()([X,X_shortcut])\n",
    "    ##使用ReLU激活函数\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8d78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s=2):\n",
    "    \"\"\"\n",
    "    实现图5的卷积块\n",
    "    \n",
    "    参数：\n",
    "        X - 输入的tensor类型的变量，维度为( m, n_H_prev, n_W_prev, n_C_prev)\n",
    "        f - 整数，指定主路径中间的CONV窗口的维度\n",
    "        filters - 整数列表，定义了主路径每层的卷积层的过滤器数量\n",
    "        stage - 整数，根据每层的位置来命名每一层，与block参数一起使用。\n",
    "        block - 字符串，据每层的位置来命名每一层，与stage参数一起使用。\n",
    "        s - 整数，指定要使用的步幅\n",
    "    \n",
    "    返回：\n",
    "        X - 卷积块的输出，tensor类型，维度为(n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    #定义命名规则\n",
    "    conv_name_base = \"res\" + str(stage) + block + \"_branch\"\n",
    "    bn_name_base   = \"bn\"  + str(stage) + block + \"_branch\"\n",
    "    \n",
    "    #获取过滤器数量\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    #保存输入数据\n",
    "    X_shortcut = X\n",
    "    \n",
    "    #主路径\n",
    "    ##主路径第一部分\n",
    "    X = Conv2D(filters=F1, kernel_size=(1,1), strides=(s,s), padding=\"valid\",\n",
    "               name=conv_name_base+\"2a\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2a\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    ##主路径第二部分\n",
    "    X = Conv2D(filters=F2, kernel_size=(f,f), strides=(1,1), padding=\"same\",\n",
    "               name=conv_name_base+\"2b\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2b\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    ##主路径第三部分\n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1), strides=(1,1), padding=\"valid\",\n",
    "               name=conv_name_base+\"2c\", kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name=bn_name_base+\"2c\")(X)\n",
    "    \n",
    "    #捷径\n",
    "    X_shortcut = Conv2D(filters=F3, kernel_size=(1,1), strides=(s,s), padding=\"valid\",\n",
    "               name=conv_name_base+\"1\", kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=3,name=bn_name_base+\"1\")(X_shortcut)\n",
    "    \n",
    "    #最后一步\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation(\"relu\")(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90625ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape=(280,280,1),classes=8):\n",
    "    \"\"\"\n",
    "    实现ResNet50\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "    \n",
    "    参数：\n",
    "        input_shape - 图像数据集的维度\n",
    "        classes - 整数，分类数\n",
    "        \n",
    "    返回：\n",
    "        model - Keras框架的模型\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #定义tensor类型的输入数据\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #0填充\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    #stage1\n",
    "    X = Conv2D(filters=64, kernel_size=(7,7), strides=(2,2), name=\"conv1\",\n",
    "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=\"bn_conv1\")(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n",
    "    \n",
    "    #stage2\n",
    "    X = convolutional_block(X, f=3, filters=[64,64,256], stage=2, block=\"a\", s=1)\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block=\"c\")\n",
    "    \n",
    "    #stage3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block=\"d\")\n",
    "    \n",
    "    #stage4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"c\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"d\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"e\")\n",
    "    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block=\"f\")\n",
    "    \n",
    "    #stage5\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block=\"a\", s=2)\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"b\")\n",
    "    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block=\"c\")\n",
    "    \n",
    "    #均值池化层\n",
    "    X = AveragePooling2D(pool_size=(2,2),padding=\"same\")(X)\n",
    "    \n",
    "    #输出层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation=\"softmax\", name=\"fc\"+str(classes),\n",
    "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    #创建模型\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"ResNet50\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc9f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From K:\\Anaconda\\envs\\mytensor\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape=(280,280,1),classes=8)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c93b900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FullZero\\AppData\\Local\\Temp\\ipykernel_2000\\1765711401.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  vector = np.array(list(reader)).astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7100, 280, 280, 1)\n",
      "X_train.shape: (5680, 280, 280, 1)\n",
      "X_test.shape: (1420, 280, 280, 1)\n",
      "Y_train.shape: (5680, 8)\n",
      "Y_test.shape: (1420, 8)\n"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件，将标签加载到一个列表中\n",
    "labels_df = pd.read_csv(\"C:\\\\Users\\\\FullZero\\\\Desktop\\\\dataset\\\\labels.csv\", header=None)\n",
    "label_dict = {label: i for i, label in enumerate(set(labels_df[0]))}\n",
    "labels = [label_dict[label] for label in labels_df[0]]\n",
    "\n",
    "# 读取二维向量数据\n",
    "vectors = []\n",
    "for i in range(1,7101):\n",
    "    with open(f\"C:\\\\Users\\\\FullZero\\\\Desktop\\\\dataset\\\\vectors\\\\{i}.txt\", 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        vector = np.array(list(reader)).astype(np.float)\n",
    "        vectors.append(vector)\n",
    "vectors = np.array(vectors)\n",
    "\n",
    "# 将二维向量转换为三维张量\n",
    "vectors = vectors.reshape((7100, 280, 280, 1))\n",
    "\n",
    "\n",
    "# 输出三维张量的形状\n",
    "print(vectors.shape)\n",
    "\n",
    "\n",
    "# 将向量和标签拆分为训练集和测试集\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(vectors, labels, test_size=0.2)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "## Convert training and test labels to one hot matrices\n",
    "Y_train = resnets_utils.convert_to_one_hot(Y_train, 8).T\n",
    "Y_test = resnets_utils.convert_to_one_hot(Y_test, 8).T\n",
    "print('X_train.shape:',X_train.shape)\n",
    "print('X_test.shape:',X_test.shape)\n",
    "print('Y_train.shape:',Y_train.shape)\n",
    "print('Y_test.shape:',Y_test.shape)\n",
    "\n",
    "\n",
    "# 标准化数据\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b46c0c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5680 samples\n",
      "Epoch 1/10\n",
      "5680/5680 [==============================] - 218s 38ms/sample - loss: 1.7749 - accuracy: 0.3415\n",
      "Epoch 2/10\n",
      "5680/5680 [==============================] - 218s 38ms/sample - loss: 1.6589 - accuracy: 0.3924\n",
      "Epoch 3/10\n",
      "5680/5680 [==============================] - 224s 39ms/sample - loss: 1.5289 - accuracy: 0.4489\n",
      "Epoch 4/10\n",
      "5680/5680 [==============================] - 223s 39ms/sample - loss: 1.4617 - accuracy: 0.4836\n",
      "Epoch 5/10\n",
      "5680/5680 [==============================] - 224s 39ms/sample - loss: 1.4415 - accuracy: 0.4850\n",
      "Epoch 6/10\n",
      "5680/5680 [==============================] - 223s 39ms/sample - loss: 1.4305 - accuracy: 0.4919\n",
      "Epoch 7/10\n",
      "5680/5680 [==============================] - 225s 40ms/sample - loss: 1.3660 - accuracy: 0.5123\n",
      "Epoch 8/10\n",
      "5680/5680 [==============================] - 245s 43ms/sample - loss: 1.3136 - accuracy: 0.5317\n",
      "Epoch 9/10\n",
      "5680/5680 [==============================] - 251s 44ms/sample - loss: 1.2630 - accuracy: 0.5556\n",
      "Epoch 10/10\n",
      "5680/5680 [==============================] - 244s 43ms/sample - loss: 1.2533 - accuracy: 0.5530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f446edf040>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=10,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9def2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "误差值 = 11.446234874993982\n",
      "准确率 = 0.119014084\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test,Y_test)\n",
    "\n",
    "print(\"误差值 = \" + str(preds[0]))\n",
    "print(\"准确率 = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723942e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
