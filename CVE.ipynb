{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d360ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# 按行合并多个Dataframe数据\n",
    "def mergeData():\n",
    "    monday = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Monday-WorkingHours.pcap_ISCX.csv\")\n",
    " \n",
    "    # 剔除第一行属性特征名称\n",
    "    #monday = monday.drop([0])\n",
    "    friday1 = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "    #friday1 = friday1.drop([0])\n",
    "    friday2 = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\")\n",
    "    #friday2 = friday2.drop([0])\n",
    "    friday3 = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
    "    #friday3 = friday3.drop([0])\n",
    "    thursday1 = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\")\n",
    "    #thursday1 = thursday1.drop([0])\n",
    "    thursday2 = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\")\n",
    "    #thursday2 = thursday2.drop([0])\n",
    "    tuesday = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "    #tuesday = tuesday.drop([0])\n",
    "    wednesday = pd.read_csv(\"K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "    #wednesday = wednesday.drop([0])\n",
    "    frame = [monday,friday1,friday2,friday3,thursday1,thursday2,tuesday,wednesday]\n",
    " \n",
    "    # 合并数据\n",
    "    result = pd.concat(frame)\n",
    "    #list = clearDirtyData(result)\n",
    "    #result = result.drop(list)\n",
    "    return result\n",
    " \n",
    " \n",
    " # 清除CIC-IDS数据集中的脏数据，第一行特征名称和含有Nan、Infiniti等数据的行数\n",
    "\n",
    "#def clearDirtyData(df):\n",
    "    #dropList = df[(df[ 'Flow Bytes/s']==\"Nan\")|(df['Flow Packets/s']==\"Infinity\")].index.tolist()\n",
    "    #return dropList\n",
    "    \n",
    "raw_data=mergeData()\n",
    "file = 'K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total.csv'\n",
    "raw_data.to_csv(file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a56c6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total.csv')\n",
    "\n",
    "# 检查第15和16列的NaN和Infinity值\n",
    "mask = np.isnan(df.iloc[:, 14]) | np.isnan(df.iloc[:, 15]) | np.isinf(df.iloc[:, 14]) | np.isinf(df.iloc[:, 15])\n",
    "\n",
    "# 删除满足条件的行\n",
    "df = df[~mask]\n",
    "\n",
    "# 保存修改后的CSV文件\n",
    "df.to_csv('K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f8e8e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENIGN                        2271320\n",
      "DoS Hulk                       230124\n",
      "PortScan                       158804\n",
      "DDoS                           128025\n",
      "DoS GoldenEye                   10293\n",
      "FTP-Patator                      7935\n",
      "SSH-Patator                      5897\n",
      "DoS slowloris                    5796\n",
      "DoS Slowhttptest                 5499\n",
      "Bot                              1956\n",
      "Web Attack � Brute Force         1507\n",
      "Web Attack � XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack � Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv('K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total2.csv')\n",
    "last_column_name = raw_data.columns[-1]  # 最后一列列名\n",
    "print(raw_data[last_column_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2a05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Destination Port\n",
      " Flow Duration\n",
      " Total Fwd Packets\n",
      " Total Backward Packets\n",
      "Total Length of Fwd Packets\n",
      " Total Length of Bwd Packets\n",
      " Fwd Packet Length Max\n",
      " Fwd Packet Length Min\n",
      " Fwd Packet Length Mean\n",
      " Fwd Packet Length Std\n",
      "Bwd Packet Length Max\n",
      " Bwd Packet Length Min\n",
      " Bwd Packet Length Mean\n",
      " Bwd Packet Length Std\n",
      "Flow Bytes/s\n",
      " Flow Packets/s\n",
      " Flow IAT Mean\n",
      " Flow IAT Std\n",
      " Flow IAT Max\n",
      " Flow IAT Min\n",
      "Fwd IAT Total\n",
      " Fwd IAT Mean\n",
      " Fwd IAT Std\n",
      " Fwd IAT Max\n",
      " Fwd IAT Min\n",
      "Bwd IAT Total\n",
      " Bwd IAT Mean\n",
      " Bwd IAT Std\n",
      " Bwd IAT Max\n",
      " Bwd IAT Min\n",
      "Fwd PSH Flags\n",
      " Bwd PSH Flags\n",
      " Fwd URG Flags\n",
      " Bwd URG Flags\n",
      " Fwd Header Length\n",
      " Bwd Header Length\n",
      "Fwd Packets/s\n",
      " Bwd Packets/s\n",
      " Min Packet Length\n",
      " Max Packet Length\n",
      " Packet Length Mean\n",
      " Packet Length Std\n",
      " Packet Length Variance\n",
      "FIN Flag Count\n",
      " SYN Flag Count\n",
      " RST Flag Count\n",
      " PSH Flag Count\n",
      " ACK Flag Count\n",
      " URG Flag Count\n",
      " CWE Flag Count\n",
      " ECE Flag Count\n",
      " Down/Up Ratio\n",
      " Average Packet Size\n",
      " Avg Fwd Segment Size\n",
      " Avg Bwd Segment Size\n",
      " Fwd Header Length.1\n",
      "Fwd Avg Bytes/Bulk\n",
      " Fwd Avg Packets/Bulk\n",
      " Fwd Avg Bulk Rate\n",
      " Bwd Avg Bytes/Bulk\n",
      " Bwd Avg Packets/Bulk\n",
      "Bwd Avg Bulk Rate\n",
      "Subflow Fwd Packets\n",
      " Subflow Fwd Bytes\n",
      " Subflow Bwd Packets\n",
      " Subflow Bwd Bytes\n",
      "Init_Win_bytes_forward\n",
      " Init_Win_bytes_backward\n",
      " act_data_pkt_fwd\n",
      " min_seg_size_forward\n",
      "Active Mean\n",
      " Active Std\n",
      " Active Max\n",
      " Active Min\n",
      "Idle Mean\n",
      " Idle Std\n",
      " Idle Max\n",
      " Idle Min\n",
      " Label\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "data_to_use = pd.read_csv('K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total2.csv')\n",
    "\n",
    "# 获取列名列表\n",
    "column_names = data_to_use.columns.tolist()\n",
    "\n",
    "# 打印列名\n",
    "for column in column_names:\n",
    "    print(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819afae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 将修改后的结果写入新的 CSV 文件\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(new_csv_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[43mnew_encoding\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_encoding' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 要处理的 CSV 文件路径\n",
    "csv_file_path = 'K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total2.csv'\n",
    "\n",
    "# 新的 CSV 文件路径\n",
    "new_csv_file_path = 'K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total3.csv'\n",
    "\n",
    "# 读取 CSV 文件并替换列头\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# 删除列头中第一个字符前的空格\n",
    "df.rename(columns=lambda x: x[1:] if x.startswith(' ') else x, inplace=True)\n",
    "\n",
    "# 将修改后的结果写入新的 CSV 文件\n",
    "df.to_csv(new_csv_file_path, index=False, encoding=new_encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2ec6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total3.csv')\n",
    "# 删除列\n",
    "columns_to_drop = ['Fwd Header Length.1']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# 保存修改后的CSV文件\n",
    "df.to_csv('K:\\\\Data\\\\MachineLearningCSV\\\\MachineLearningCVE\\\\total4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e499ff9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
